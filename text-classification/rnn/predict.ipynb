{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrRsuybsbpIHv5v99yu3fk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# H5 file"
      ],
      "metadata": {
        "id": "jHIPRl6jutj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "NuEzFgDUFpRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Books', 'Clothing & Accessories', 'Electronics', 'Household']\n",
        "seq_len = 120"
      ],
      "metadata": {
        "id": "V0crzEGKrKxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmdMt5Mhi_AX",
        "outputId": "e4d9f41d-ac38-40de-c2db-867738834cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp_base_dir = \"/gdrive/MyDrive/ESTIAM/E5/AI-ML-Model-Design/TP-Model-Backup\"\n",
        "model_file_path = f\"{tp_base_dir}/rnn_model.h5\"\n",
        "tokenizer_file_path = f\"{tp_base_dir}/tokenizer.json\""
      ],
      "metadata": {
        "id": "MqgIV7x5b2Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(tokenizer_file_path, \"r\") as tokenizer_file:\n",
        "    tokenizer_json = json.load(tokenizer_file)\n",
        "\n",
        "tokenizer: Tokenizer = tokenizer_from_json(tokenizer_json)"
      ],
      "metadata": {
        "id": "yoWfhtzvqjIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"Dell 19.5V-3.34AMP 65W Laptop Adapter\",\n",
        "    \"Women's Stretchable Viscose\",\n",
        "    \"Paper Plane Design Framed Wall Hanging\",\n",
        "    \"The art of War\",\n",
        "]\n",
        "\n",
        "samples_seq = tokenizer.texts_to_sequences(samples)\n",
        "samples_pad = pad_sequences(samples_seq, maxlen=seq_len)"
      ],
      "metadata": {
        "id": "QjsW6IOq56LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_rnn_model = tf.keras.models.load_model(model_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXYhbcCGdFm_",
        "outputId": "21985026-d512-4460-f53d-ad31bf82cc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_id = 0\n",
        "x = samples_pad[x_id]\n",
        "x = np.array([x])\n",
        "x_logits = loaded_rnn_model.predict(x)\n",
        "\n",
        "preds = np.argmax(x_logits, axis=1)\n",
        "output = preds[0]\n",
        "\n",
        "print(\"Text :\", samples[x_id])\n",
        "print(\"Predicted Label :\", output)\n",
        "print(\"Predicted Class :\", labels[output])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcVlQ0L9s5FF",
        "outputId": "02690c4b-964f-4a1a-8146-fc76c0899a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b35711e7f60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
            "Text : Dell 19.5V-3.34AMP 65W Laptop Adapter\n",
            "Predicted Label : 2\n",
            "Predicted Class : Electronics\n",
            "\n"
          ]
        }
      ]
    }
  ]
}